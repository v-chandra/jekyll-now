---
layout: page
title: Selected Recent Publications
permalink: /publications/
---

1. NASGEM: Neural architecture search via graph embedding method,
*arXiv (2020)*. [[Paper]](https://arxiv.org/pdf/2007.04452.pdf).

1. DNA: Differentiable Network-Accelerator Co-Search,
*arXiv (2020)*. [Paper](https://arxiv.org/pdf/2010.14778.pdf).

1. One weight bitwidth to rule them all,
*Embedded Vision Workshop, ECCV 2020*. [Paper](https://arxiv.org/pdf/2008.09916.pdf).

1. Co-Exploration of Neural Architectures and Heterogeneous ASIC Accelerator 
Designs Targeting Multiple Tasks,
*DAC 2020*. [Paper](https://arxiv.org/pdf/2002.04116.pdf).

1. RecNMP: Accelerating Personalized Recommendation with Near-Memory Processing,
*ISCA 2020*. [Paper](https://arxiv.org/pdf/1912.12953.pdf).

1. Energy-Aware Neural Architecture Optimization With Splitting Steepest Descent, 
*Workshop on Energy Efficient Machine Learning and Cognitive Computing, NeurIPS (2019)*. [Paper](https://arxiv.org/pdf/1910.03103.pdf).

1. Improving Efficiency in Neural Network Accelerator using Operands Hamming Distance Optimization,
*Workshop on Energy Efficient Machine Learning and Cognitive Computing, NeurIPS (2019)*. [Paper](https://arxiv.org/pdf/2002.05293.pdf).

1. HERALD: Optimizing Heterogeneous DNN Accelerators for Edge Devices,
*arXiv (2019)*. [Paper](https://arxiv.org/pdf/1909.07437.pdf).

1. Federated learning with non-iid data,
*arXiv (2018)*. [Paper](https://arxiv.org/pdf/1806.00582.pdf).

1. CMSIS-NN: Efficient Neural Network Kernels for Arm Cortex-M CPUs,
*arXiv (2018)*. [Paper](https://arxiv.org/abs/1801.06601).

1. Not All Ops are Created Equal!,
*arXiv (2018)*. [Paper](https://arxiv.org/abs/1801.04326).

1. PrivyNet: A Flexible Framework for Privacy-Preserving Deep Neural Network Training,
*arXiv (2018)*. [Paper](https://arxiv.org/abs/1709.06161).

1. Bit Fusion: Bit-Level Dynamically Composable Architecture for Accelerating Deep Neural Networks, 
*International Symposium on Computer Architecture, 2018*. [Paper](https://arxiv.org/abs/1712.01507).

1. Hello Edge: Keyword Spotting on Microcontrollers, 
*arXiv (2017)*. [Paper](https://arxiv.org/abs/1711.07128).

1. Deep Convolutional Neural Network Inference with Floating-point Weights and Fixed-point Activations,
*arXiv (2017)*. [Paper](https://arxiv.org/abs/1703.03073).

1. Throughput-optimized OpenCL-based FPGA accelerator for large-scale convolutional neural networks,
*FPGA Conference (2016)*. [Paper](https://dl.acm.org/citation.cfm?id=2847276).
