---
layout: page
title: Selected Recent Publications
permalink: /publications/
---

1. Energy-Aware Neural Architecture Optimization With Splitting Steepest Descent, 
*Workshop on Energy Efficient Machine Learning and Cognitive Computing, NeurIPS (2019)*. [Paper](https://arxiv.org/pdf/1910.03103.pdf).

1. Improving Efficiency in Neural Network Accelerator using Operands Hamming Distance Optimization,
*Workshop on Energy Efficient Machine Learning and Cognitive Computing, NeurIPS (2019)*. [Paper](https://www.emc2-workshop.com/assets/docs/neurips-19/emc2-paper-30.pdf).

1. HERALD: Optimizing Heterogeneous DNN Accelerators for Edge Devices,
*arXiv (2019)*. [Paper](https://arxiv.org/pdf/1909.07437.pdf).

1. Federated learning with non-iid data,
*arXiv (2018)*. [Paper](https://arxiv.org/pdf/1806.00582.pdf).

1. CMSIS-NN: Efficient Neural Network Kernels for Arm Cortex-M CPUs,
*arXiv (2018)*. [Paper](https://arxiv.org/abs/1801.06601).

1. Not All Ops are Created Equal!,
*arXiv (2018)*. [Paper](https://arxiv.org/abs/1801.04326).

1. PrivyNet: A Flexible Framework for Privacy-Preserving Deep Neural Network Training,
*arXiv (2018)*. [Paper](https://arxiv.org/abs/1709.06161).

1. Bit Fusion: Bit-Level Dynamically Composable Architecture for Accelerating Deep Neural Networks, 
*International Symposium on Computer Architecture, 2018*. [Paper](https://arxiv.org/abs/1712.01507).

1. Hello Edge: Keyword Spotting on Microcontrollers, 
*arXiv (2017)*. [Paper](https://arxiv.org/abs/1711.07128).

1. Deep Convolutional Neural Network Inference with Floating-point Weights and Fixed-point Activations,
*arXiv (2017)*. [Paper](https://arxiv.org/abs/1703.03073).

1. Throughput-optimized OpenCL-based FPGA accelerator for large-scale convolutional neural networks,
*FPGA Conference (2016)*. [Paper](https://dl.acm.org/citation.cfm?id=2847276).
